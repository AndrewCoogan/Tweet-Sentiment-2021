{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%config Completer.use_jedi = False\n",
    "# Jupyter notebook autocomplete was not working.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "    \n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "# from spacy.gold import GoldParse # For use in nlp.update\n",
    "# from spacy.training.example import Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id       Entity Sentiment  \\\n",
       "0  2401  Borderlands  Positive   \n",
       "1  2401  Borderlands  Positive   \n",
       "2  2401  Borderlands  Positive   \n",
       "3  2401  Borderlands  Positive   \n",
       "4  2401  Borderlands  Positive   \n",
       "\n",
       "                                             Content  \n",
       "0  im getting on borderlands and i will murder yo...  \n",
       "1  I am coming to the borders and I will kill you...  \n",
       "2  im getting on borderlands and i will kill you ...  \n",
       "3  im coming on borderlands and i will murder you...  \n",
       "4  im getting on borderlands 2 and i will murder ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('Data/twitter_training.csv', header = None)\n",
    "train.columns = ['Id', 'Entity', 'Sentiment', 'Content']\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3364</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>I mentioned on Facebook that I was struggling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>352</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>BBC News - Amazon boss Jeff Bezos rejects clai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8312</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Negative</td>\n",
       "      <td>@Microsoft Why do I pay for WORD when it funct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4371</td>\n",
       "      <td>CS-GO</td>\n",
       "      <td>Negative</td>\n",
       "      <td>CSGO matchmaking is so full of closet hacking,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4433</td>\n",
       "      <td>Google</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Now the President is slapping Americans in the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id     Entity   Sentiment  \\\n",
       "0  3364   Facebook  Irrelevant   \n",
       "1   352     Amazon     Neutral   \n",
       "2  8312  Microsoft    Negative   \n",
       "3  4371      CS-GO    Negative   \n",
       "4  4433     Google     Neutral   \n",
       "\n",
       "                                             Content  \n",
       "0  I mentioned on Facebook that I was struggling ...  \n",
       "1  BBC News - Amazon boss Jeff Bezos rejects clai...  \n",
       "2  @Microsoft Why do I pay for WORD when it funct...  \n",
       "3  CSGO matchmaking is so full of closet hacking,...  \n",
       "4  Now the President is slapping Americans in the...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate = pd.read_csv('Data/twitter_validation.csv', header = None)\n",
    "validate.columns = ['Id', 'Entity', 'Sentiment', 'Content']\n",
    "validate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative      22542\n",
       "Positive      20832\n",
       "Neutral       18318\n",
       "Irrelevant    12990\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative      0.301840\n",
       "Positive      0.278943\n",
       "Neutral       0.245280\n",
       "Irrelevant    0.173937\n",
       "Name: Sentiment, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Sentiment.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Microsoft                            2400\n",
       "TomClancysRainbowSix                 2400\n",
       "MaddenNFL                            2400\n",
       "CallOfDuty                           2394\n",
       "LeagueOfLegends                      2394\n",
       "Verizon                              2382\n",
       "CallOfDutyBlackopsColdWar            2376\n",
       "ApexLegends                          2376\n",
       "Facebook                             2370\n",
       "WorldOfCraft                         2364\n",
       "Dota2                                2364\n",
       "NBA2K                                2352\n",
       "TomClancysGhostRecon                 2346\n",
       "Battlefield                          2346\n",
       "FIFA                                 2340\n",
       "Overwatch                            2334\n",
       "Xbox(Xseries)                        2334\n",
       "johnson&johnson                      2328\n",
       "Amazon                               2316\n",
       "PlayStation5(PS5)                    2310\n",
       "HomeDepot                            2310\n",
       "GrandTheftAuto(GTA)                  2304\n",
       "CS-GO                                2304\n",
       "Cyberpunk2077                        2304\n",
       "Google                               2298\n",
       "Hearthstone                          2298\n",
       "Nvidia                               2298\n",
       "Borderlands                          2286\n",
       "Fortnite                             2274\n",
       "PlayerUnknownsBattlegrounds(PUBG)    2274\n",
       "RedDeadRedemption(RDR)               2262\n",
       "AssassinsCreed                       2244\n",
       "Name: Entity, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Entity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diff of training and validate: []\n",
      "Diff of validate and training: []\n"
     ]
    }
   ],
   "source": [
    "# Should we create new models for each Entity?\n",
    "# Lets see if there are any entities in the train and/or test that are not in the other set.\n",
    "entity_values = list(set(train.Entity.values.tolist()))\n",
    "validation_values = list(set(validate.Entity.values.tolist()))\n",
    "\n",
    "def diff_of_two_lists(list1 : list, list2 : list) -> list:\n",
    "    return list(set(list1) - set(list2))\n",
    "\n",
    "in_train_not_validate = diff_of_two_lists(entity_values, validation_values)\n",
    "in_validate_not_train = diff_of_two_lists(validation_values, entity_values)\n",
    "\n",
    "print(f'Diff of training and validate: {in_train_not_validate}')\n",
    "print(f'Diff of validate and training: {in_validate_not_train}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Broad Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_chars(text : str) -> str:\n",
    "    '''This will remove special characters from a string'''\n",
    "    return re.sub('[^A-Za-z0-9]+', '', text)\n",
    "\n",
    "def clean_text(text : str) -> str:\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = text.lower() # make everythng lowercase\n",
    "    text = re.sub('\\[.*?\\]', '', text) # remove text in squre brackets\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text) # remove website links\n",
    "    text = re.sub('<.*?>+', '', text) # remove anything within <...>\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) # remove punctuation\n",
    "    text = re.sub('\\n', '', text) # remove new line \n",
    "    text = re.sub('\\w*\\d\\w*', '', text) # remove words containing numbers\n",
    "    \n",
    "    return text\n",
    "\n",
    "def text_preprocessing(text : str, remove_duplicate : bool = False, remove_stop_words : bool = False) -> str:\n",
    "    '''This takes a string, implements clean_text, and tokenizes the workds into a list.\n",
    "    This can also remove duplicated words, but also remove stop words.'''  \n",
    "    \n",
    "    ### TODO: Update this to be all in the Spacy framework, i.e. drop NLTK\n",
    "    \n",
    "    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "    nopunc = clean_text(text)\n",
    "    tokenized_text = tokenizer.tokenize(nopunc)\n",
    "    \n",
    "    # If remove_duplicates is used, order is lost\n",
    "    if remove_duplicate: \n",
    "        tokenized_text = list(set(tokenized_text))\n",
    "    \n",
    "    ### Where (if at all) should we remove the stop words, i.e., before we clean the text?  Dont and don't are diff.\n",
    "    if remove_stop_words:\n",
    "        tokenized_text = [w for w in tokenized_text if w not in stopwords.words('english')]\n",
    "    \n",
    "    combined_text = ' '.join(tokenized_text)\n",
    "    \n",
    "    return combined_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Slightly More Specific Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweets(data : pd.DataFrame) -> pd.DataFrame:\n",
    "    data['Content_Clean'] = data['Content'].apply(str).apply(lambda x : text_preprocessing(x))\n",
    "    data['Entity_Clean'] = data['Entity'].apply(str).apply(lambda x : text_preprocessing(x))\n",
    "    data['Sentiment'] = data['Sentiment'].apply(str).apply(lambda x : x.upper())\n",
    "    \n",
    "    data['cats'] = [{\n",
    "            \"POSITIVE\" : sentiment == \"POSITIVE\",\n",
    "            \"NEUTRAL\" : sentiment == \"NEUTRAL\",\n",
    "            \"NEGATIVE\" : sentiment == \"NEGATIVE\",\n",
    "            \"IRRELEVANT\" : sentiment == \"IRRELEVANT\",\n",
    "        } \n",
    "        for sentiment in data.Sentiment\n",
    "    ]\n",
    "    \n",
    "    return data\n",
    "\n",
    "#  This needs to be vetted and updated to our scenario.\n",
    "def evaluate(tokenizer, textcat, texts, cats):\n",
    "    docs = (tokenizer(text) for text in texts)\n",
    "    tp = 0.0   # True positives\n",
    "    fp = 1e-8  # False positives\n",
    "    fn = 1e-8  # False negatives\n",
    "    tn = 0.0   # True negatives\n",
    "    for i, doc in enumerate(textcat.pipe(docs)):\n",
    "        gold = cats[i]\n",
    "        for label, score in doc.cats.items():\n",
    "            if label not in gold:\n",
    "                continue\n",
    "            if label == \"NEGATIVE\":\n",
    "                continue\n",
    "            if score >= 0.5 and gold[label] >= 0.5:\n",
    "                tp += 1.0\n",
    "            elif score >= 0.5 and gold[label] < 0.5:\n",
    "                fp += 1.0\n",
    "            elif score < 0.5 and gold[label] < 0.5:\n",
    "                tn += 1\n",
    "            elif score < 0.5 and gold[label] >= 0.5:\n",
    "                fn += 1\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    if (precision + recall) == 0:\n",
    "        f_score = 0.0\n",
    "    else:\n",
    "        f_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return {\"textcat_p\": precision, \"textcat_r\": recall, \"textcat_f\": f_score}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Irrelevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Amazon</td>\n",
       "      <td>0.135325</td>\n",
       "      <td>0.252636</td>\n",
       "      <td>0.530316</td>\n",
       "      <td>0.081722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ApexLegends</td>\n",
       "      <td>0.269443</td>\n",
       "      <td>0.251169</td>\n",
       "      <td>0.397790</td>\n",
       "      <td>0.081598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AssassinsCreed</td>\n",
       "      <td>0.644136</td>\n",
       "      <td>0.167860</td>\n",
       "      <td>0.069830</td>\n",
       "      <td>0.118174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Battlefield</td>\n",
       "      <td>0.253022</td>\n",
       "      <td>0.200345</td>\n",
       "      <td>0.151554</td>\n",
       "      <td>0.395078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Borderlands</td>\n",
       "      <td>0.446053</td>\n",
       "      <td>0.186842</td>\n",
       "      <td>0.261842</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Positive  Negative   Neutral  Irrelevant\n",
       "Amazon          0.135325  0.252636  0.530316    0.081722\n",
       "ApexLegends     0.269443  0.251169  0.397790    0.081598\n",
       "AssassinsCreed  0.644136  0.167860  0.069830    0.118174\n",
       "Battlefield     0.253022  0.200345  0.151554    0.395078\n",
       "Borderlands     0.446053  0.186842  0.261842    0.105263"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_count = train.\\\n",
    "    groupby(['Entity', 'Sentiment']).count()['Content'].reset_index().\\\n",
    "    sort_values(by = ['Entity', 'Sentiment'], ascending = True)\n",
    "\n",
    "train_count_df = pd.DataFrame(columns = ['Positive', 'Negative', 'Neutral', 'Irrelevant'])\n",
    "\n",
    "for _, row in train_count.iterrows():\n",
    "    train_count_df.loc[row.Entity, row.Sentiment] = row.Content\n",
    "\n",
    "train_count_pct_df = train_count_df.div(train_count_df.sum(axis = 1), axis = 0)\n",
    "\n",
    "train_count_pct_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Irrelevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>AssassinsCreed</td>\n",
       "      <td>0.644136</td>\n",
       "      <td>0.167860</td>\n",
       "      <td>0.069830</td>\n",
       "      <td>0.118174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MaddenNFL</td>\n",
       "      <td>0.166597</td>\n",
       "      <td>0.712663</td>\n",
       "      <td>0.082878</td>\n",
       "      <td>0.037863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Amazon</td>\n",
       "      <td>0.135325</td>\n",
       "      <td>0.252636</td>\n",
       "      <td>0.530316</td>\n",
       "      <td>0.081722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PlayerUnknownsBattlegrounds(PUBG)</td>\n",
       "      <td>0.178156</td>\n",
       "      <td>0.303491</td>\n",
       "      <td>0.117726</td>\n",
       "      <td>0.400627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Positive  Negative   Neutral  Irrelevant\n",
       "AssassinsCreed                     0.644136  0.167860  0.069830    0.118174\n",
       "MaddenNFL                          0.166597  0.712663  0.082878    0.037863\n",
       "Amazon                             0.135325  0.252636  0.530316    0.081722\n",
       "PlayerUnknownsBattlegrounds(PUBG)  0.178156  0.303491  0.117726    0.400627"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_count_pct_df.loc[train_count_pct_df.idxmax().values, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Positive has a mean of 0.280 with a standard deviation of 0.113\n",
      "Sentiment Negative has a mean of 0.301 with a standard deviation of 0.135\n",
      "Sentiment Neutral has a mean of 0.244 with a standard deviation of 0.125\n",
      "Sentiment Irrelevant has a mean of 0.175 with a standard deviation of 0.113\n"
     ]
    }
   ],
   "source": [
    "train_avg = train_count_pct_df.apply(np.mean, axis = 0)\n",
    "train_std = train_count_pct_df.apply(np.std, axis = 0)\n",
    "\n",
    "for idx, value in train_avg.iteritems():\n",
    "    print(f'Sentiment {idx} has a mean of {value:.3f} with a standard deviation of {train_std[idx]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we know that each Entity has approximately the same number of samples (2400), but the distribution between Positive, Negative, Neutral, and Irrelevant can be very different.  I suspect that we will need multiple models for each Entity, but I am going to try a few things.\n",
    "\n",
    "I am going to start with simple, one model for all of them.  I am going to try and think of a way to use the Entity as an additionl parameter, but will probably end up moving to a model for each entity, which seems inefficient, so additional considerations might be needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Preprocessing\n",
    "\n",
    "Here we are going to simply apply the text cleaning logic that we established above.  We obviously need to do this for the Content text itself, but I also want to do it for the Entity.  Eventually, I expect that we will need to create separate models for each entity and want the model names to be simple and consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Content</th>\n",
       "      <th>Content_Clean</th>\n",
       "      <th>Entity_Clean</th>\n",
       "      <th>cats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "      <td>borderlands</td>\n",
       "      <td>{'POSITIVE': True, 'NEUTRAL': False, 'NEGATIVE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td>i am coming to the borders and i will kill you...</td>\n",
       "      <td>borderlands</td>\n",
       "      <td>{'POSITIVE': True, 'NEUTRAL': False, 'NEGATIVE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td>im getting on borderlands and i will kill you all</td>\n",
       "      <td>borderlands</td>\n",
       "      <td>{'POSITIVE': True, 'NEUTRAL': False, 'NEGATIVE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>borderlands</td>\n",
       "      <td>{'POSITIVE': True, 'NEUTRAL': False, 'NEGATIVE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "      <td>borderlands</td>\n",
       "      <td>{'POSITIVE': True, 'NEUTRAL': False, 'NEGATIVE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id       Entity Sentiment  \\\n",
       "0  2401  Borderlands  POSITIVE   \n",
       "1  2401  Borderlands  POSITIVE   \n",
       "2  2401  Borderlands  POSITIVE   \n",
       "3  2401  Borderlands  POSITIVE   \n",
       "4  2401  Borderlands  POSITIVE   \n",
       "\n",
       "                                             Content  \\\n",
       "0  im getting on borderlands and i will murder yo...   \n",
       "1  I am coming to the borders and I will kill you...   \n",
       "2  im getting on borderlands and i will kill you ...   \n",
       "3  im coming on borderlands and i will murder you...   \n",
       "4  im getting on borderlands 2 and i will murder ...   \n",
       "\n",
       "                                       Content_Clean Entity_Clean  \\\n",
       "0  im getting on borderlands and i will murder yo...  borderlands   \n",
       "1  i am coming to the borders and i will kill you...  borderlands   \n",
       "2  im getting on borderlands and i will kill you all  borderlands   \n",
       "3  im coming on borderlands and i will murder you...  borderlands   \n",
       "4  im getting on borderlands and i will murder yo...  borderlands   \n",
       "\n",
       "                                                cats  \n",
       "0  {'POSITIVE': True, 'NEUTRAL': False, 'NEGATIVE...  \n",
       "1  {'POSITIVE': True, 'NEUTRAL': False, 'NEGATIVE...  \n",
       "2  {'POSITIVE': True, 'NEUTRAL': False, 'NEGATIVE...  \n",
       "3  {'POSITIVE': True, 'NEUTRAL': False, 'NEGATIVE...  \n",
       "4  {'POSITIVE': True, 'NEUTRAL': False, 'NEGATIVE...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clean = process_tweets(train)\n",
    "validate_clean = process_tweets(validate)\n",
    "\n",
    "train_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('im getting into borderlands and i can murder you all',\n",
       "  {'POSITIVE': True,\n",
       "   'NEUTRAL': False,\n",
       "   'NEGATIVE': False,\n",
       "   'IRRELEVANT': False}),\n",
       " ('so i spent a few hours making something for fun if you dont know i am a huge borderlands fan and maya is one of my favorite characters so i decided to make myself a wallpaper for my pc here is the original image versus the creation i made enjoy',\n",
       "  {'POSITIVE': True,\n",
       "   'NEUTRAL': False,\n",
       "   'NEGATIVE': False,\n",
       "   'IRRELEVANT': False})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_F = list(zip(train_clean.Content_Clean, train_clean.cats))\n",
    "validate_F = list(zip(validate_clean.Content_Clean, validate_clean.cats))\n",
    "\n",
    "train_F[5:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Very Basic, Singular Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This actually became a bit more complicated than expected.  Typically in sentiment analysis, we can do a model that has zero for negative and one for positive.  The range between them can be seen as the \"confidence\" in the model for that specific input.  In this case, however, we have FOUR possibilities, so we need to have something a bit different -- custom text classifications.\n",
    "\n",
    "https://www.machinelearningplus.com/nlp/custom-text-classification-spacy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl (13.6 MB)\n",
      "     |████████████████████████████████| 13.6 MB 6.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from en-core-web-sm==3.1.0) (3.1.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.45.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.3)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.10)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.17.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.22.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (21.0)\n",
      "Requirement already satisfied: jinja2 in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.10.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.4.1)\n",
      "Requirement already satisfied: setuptools in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (41.4.0)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.10.0.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.2)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.2.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.24.2)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.23)\n",
      "Requirement already satisfied: more-itertools in /Users/andrewcoogan/opt/anaconda3/lib/python3.7/site-packages (from zipp>=0.5->catalogue<2.1.0,>=2.0.6->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (7.2.0)\n",
      "Installing collected packages: en-core-web-sm\n",
      "  Attempting uninstall: en-core-web-sm\n",
      "    Found existing installation: en-core-web-sm 2.3.1\n",
      "    Uninstalling en-core-web-sm-2.3.1:\n",
      "      Successfully uninstalled en-core-web-sm-2.3.1\n",
      "Successfully installed en-core-web-sm-3.1.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConfigValidationError",
     "evalue": "\n\nConfig validation error\n\ntextcat -> architecture        extra fields not permitted\ntextcat -> exclusive_classes   extra fields not permitted\n\n{'nlp': <spacy.lang.en.English object at 0x7f8ff1ce2610>, 'name': 'textcat', 'architecture': 'simple_cnn', 'exclusive_classes': True, 'model': {'@architectures': 'spacy.TextCatEnsemble.v2', 'linear_model': {'@architectures': 'spacy.TextCatBOW.v2', 'exclusive_classes': True, 'ngram_size': 1, 'no_output_layer': False}, 'tok2vec': {'@architectures': 'spacy.Tok2Vec.v2', 'embed': {'@architectures': 'spacy.MultiHashEmbed.v2', 'width': 64, 'rows': [2000, 2000, 1000, 1000, 1000, 1000], 'attrs': ['ORTH', 'LOWER', 'PREFIX', 'SUFFIX', 'SHAPE', 'ID'], 'include_static_vectors': False}, 'encode': {'@architectures': 'spacy.MaxoutWindowEncoder.v2', 'width': 64, 'window_size': 1, 'maxout_pieces': 3, 'depth': 2}}}, 'threshold': 0.5, '@factories': 'textcat'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConfigValidationError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-9ccb4fb35e46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en_core_web_sm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtextcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"textcat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"exclusive_classes\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"architecture\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m\"simple_cnn\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtextcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mcreate_pipe\u001b[0;34m(self, factory_name, name, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0;31m# We're calling the internal _fill here to avoid constructing the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0;31m# registered functions twice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m         \u001b[0mresolved\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m         \u001b[0mfilled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"cfg\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfactory_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cfg\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0mfilled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/thinc/config.py\u001b[0m in \u001b[0;36mresolve\u001b[0;34m(cls, config, schema, overrides, validate)\u001b[0m\n\u001b[1;32m    728\u001b[0m     ) -> Dict[str, Any]:\n\u001b[1;32m    729\u001b[0m         resolved, _ = cls._make(\n\u001b[0;32m--> 730\u001b[0;31m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolve\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m         )\n\u001b[1;32m    732\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresolved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/thinc/config.py\u001b[0m in \u001b[0;36m_make\u001b[0;34m(cls, config, schema, overrides, resolve, validate)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         filled, _, resolved = cls._fill(\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolve\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m         )\n\u001b[1;32m    781\u001b[0m         \u001b[0mfilled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msection_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msection_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/thinc/config.py\u001b[0m in \u001b[0;36m_fill\u001b[0;34m(cls, config, schema, validate, resolve, parent, overrides)\u001b[0m\n\u001b[1;32m    837\u001b[0m                     \u001b[0mresolve\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m                     \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_parent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m                     \u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m                 )\n\u001b[1;32m    841\u001b[0m                 \u001b[0mreg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/thinc/config.py\u001b[0m in \u001b[0;36m_fill\u001b[0;34m(cls, config, schema, validate, resolve, parent, overrides)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 raise ConfigValidationError(\n\u001b[1;32m    900\u001b[0m                     \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 ) from None\n\u001b[0m\u001b[1;32m    902\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0;31m# Same as parse_obj, but without validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConfigValidationError\u001b[0m: \n\nConfig validation error\n\ntextcat -> architecture        extra fields not permitted\ntextcat -> exclusive_classes   extra fields not permitted\n\n{'nlp': <spacy.lang.en.English object at 0x7f8ff1ce2610>, 'name': 'textcat', 'architecture': 'simple_cnn', 'exclusive_classes': True, 'model': {'@architectures': 'spacy.TextCatEnsemble.v2', 'linear_model': {'@architectures': 'spacy.TextCatBOW.v2', 'exclusive_classes': True, 'ngram_size': 1, 'no_output_layer': False}, 'tok2vec': {'@architectures': 'spacy.Tok2Vec.v2', 'embed': {'@architectures': 'spacy.MultiHashEmbed.v2', 'width': 64, 'rows': [2000, 2000, 1000, 1000, 1000, 1000], 'attrs': ['ORTH', 'LOWER', 'PREFIX', 'SUFFIX', 'SHAPE', 'ID'], 'include_static_vectors': False}, 'encode': {'@architectures': 'spacy.MaxoutWindowEncoder.v2', 'width': 64, 'window_size': 1, 'maxout_pieces': 3, 'depth': 2}}}, 'threshold': 0.5, '@factories': 'textcat'}"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "textcat = nlp.create_pipe(\"textcat\", config = {\"exclusive_classes\" : True, \"architecture\" : \"simple_cnn\"})\n",
    "nlp.add_pipe(textcat, last = True)\n",
    "\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('POSITIVE', 'NEUTRAL', 'NEGATIVE', 'IRRELEVANT')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments = train_clean.Sentiment.unique().tolist()\n",
    "\n",
    "for sentiment in sentiments:\n",
    "    textcat.add_label(sentiment)\n",
    "    \n",
    "textcat.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-cd49baee5023>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_F\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompounding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                 \u001b[0;31m#texts = nlp.make_doc(texts)    #<--- add this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0;31m#gold = GoldParse(text, entities = annotations)  #<--- add this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/62486950/spacy-training-model\n",
    "\n",
    "n_iter = 10\n",
    "\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'textcat']\n",
    "with nlp.disable_pipes(*other_pipes):\n",
    "    nlp.begin_training()\n",
    "    \n",
    "    # Performing training\n",
    "    for i in range(n_iter):\n",
    "        losses = {}\n",
    "        batches = minibatch(train_F, size = compounding(10., 64., 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            texts = nlp.make_doc(texts)    #<--- add this\n",
    "            gold = GoldParse(text, entities = annotations)  #<--- add this\n",
    "            nlp.update(texts, annotations, sgd = \"optimizer\") #drop = 0.2, losses = losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
